# -*- coding: utf-8 -*-
"""customer-churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PeDqTggxp4Z88mF22gvKWZvLOPCqFsxQ
"""

import pandas as pd
df =pd.read_csv('/content/customer-churn.csv')

df.head()

print(df.shape)

pd.set_option('display.max_columns',None)

df.head()

df.drop(columns=['customerID'],inplace=True)

df.shape #colum customer-id drop

print(df['gender'].unique())

print(df['SeniorCitizen'].unique())

numerical_col=['tenure' , 'MonthlyCharges' ,'TotalCharges' ]
for col in df.columns:
  if col not in numerical_col:
    print(col, df[col].unique())
    print("_" *30)

print(df.isnull().sum())

df[df["TotalCharges"]==" "]

len(df[df["TotalCharges"]==" "])

df["TotalCharges"]=df["TotalCharges"].replace({' ': '0.0'})

df["TotalCharges"] = df["TotalCharges"].astype(float)

df.info()

print(df['Churn'].value_counts())

df.describe()

import matplotlib.pyplot as plt
import seaborn as sns
def plot(df, column_name):
  plt.figure(figsize=(5,3))
  sns.histplot(df[column_name], kde=True)
  plt.title(f'Distribution of {column_name}')

  col_mean =df[column_name].mean()
  col_median=df[column_name].median()
  col_std=df[column_name].std()

  plt.axvline(col_mean , color='red' , linestyle='--' ,label='Mean')
  plt.axvline(col_median , color='green' , linestyle='-' , label='Median')

  plt.legend()
  plt.show()

plot(df , 'tenure')

plot(df, "TotalCharges")

plot(df, "MonthlyCharges")

def box(df, column_name):
  plt.figure(figsize=(5,3))
  sns.boxplot(df[column_name])
  plt.title(f'Distribution of {column_name}')
  plt.show()

box(df, "MonthlyCharges")
box(df, "tenure")
box(df, "TotalCharges")

plt.figure(figsize=(8,5))
sns.heatmap(df[["tenure", "MonthlyCharges", "TotalCharges"]].corr(), annot=True, cmap="coolwarm", fmt='.2f')
plt.show()

df.columns

obj_cols = df.select_dtypes(include="object").columns.to_list()
obj_cols = ["SeniorCitizen"] + obj_cols
for col in obj_cols:
  plt.figure(figsize=(5,3))
  sns.countplot(x=df[col])
  plt.title(f'Distribution {col}')
  plt.show()

df.head()

df['Churn']=df['Churn'].replace({'Yes':1, 'No':0})

df.head()

print(df["Churn"].value_counts())

obj_cols=df.select_dtypes(include='object').columns

from sklearn.preprocessing import LabelEncoder
import pickle

encoder={}
for col in obj_cols:
  label_encoder =LabelEncoder()
  df[col]=label_encoder.fit_transform(df[col])
  encoder[col]=label_encoder

  with open("encoder.pkl" , "wb") as f:
    pickle.dump(encoder,f)

encoder

df.head()

# splitting the features and target
X = df.drop(columns=["Churn"])
y = df["Churn"]

from sklearn.model_selection import train_test_split , cross_val_score
# split training and test data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train.shape)

print(y_train.shape)

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.neighbors import KNeighborsClassifier

models ={
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "XGBoost": XGBClassifier(random_state=42)
}

# dictionary to store the cross validation results
import numpy as np
cv_scores = {}

# perform 5-fold cross validation for each model
for model_name, model in models.items():
  print(f"Training {model_name} with default parameters")
  scores = cross_val_score(model, X_train, y_train, cv=5, scoring="accuracy")
  cv_scores[model_name] = scores
  print(f"{model_name} cross-validation accuracy: {np.mean(scores):.2f}")
  print("-"*70)

rfc = RandomForestClassifier(random_state=42)
rfc.fit(X_train, y_train)

y_test_pred = rfc.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
print("Accuracy Score is : \n", accuracy_score(y_test, y_test_pred))
print("Classification Report is : \n", classification_report(y_test, y_test_pred))
print("Confusion Matrix is : \n" ,confusion_matrix(y_test, y_test_pred))

model_data = {"model": rfc, "features_names": X.columns.tolist()}

# load teh saved model and the feature names

with open("customer_churn_model.pkl", "rb") as f:
  model_data = pickle.load(f)

loaded_model = model_data["model"]
feature_names = model_data["features_names"]

# save the trained model as a pickle file
model_data = {"model": rfc, "features_names": X.columns.tolist()}


with open("customer_churn_model.pkl", "wb") as f:
  pickle.dump(model_data, f)

input_data = {
    'gender': 'Female',
    'SeniorCitizen': 0,
    'Partner': 'Yes',
    'Dependents': 'No',
    'tenure': 1,
    'PhoneService': 'No',
    'MultipleLines': 'No phone service',
    'InternetService': 'DSL',
    'OnlineSecurity': 'No',
    'OnlineBackup': 'Yes',
    'DeviceProtection': 'No',
    'TechSupport': 'No',
    'StreamingTV': 'No',
    'StreamingMovies': 'No',
    'Contract': 'Month-to-month',
    'PaperlessBilling': 'Yes',
    'PaymentMethod': 'Electronic check',
    'MonthlyCharges': 29.85,
    'TotalCharges': 29.85
}


input_data_df = pd.DataFrame([input_data])

with open("encoder.pkl", "rb") as f:
  encoders = pickle.load(f)


# encode categorical featires using teh saved encoders
for column, encoder in encoders.items():
  input_data_df[column] = encoder.transform(input_data_df[column])

# make a prediction
prediction = loaded_model.predict(input_data_df)
pred_prob = loaded_model.predict_proba(input_data_df)

print(prediction)

# results
print(f"Prediction: {'Churn' if prediction[0] == 1 else 'No Churn'}")
print(f"Prediciton Probability: {pred_prob}")
